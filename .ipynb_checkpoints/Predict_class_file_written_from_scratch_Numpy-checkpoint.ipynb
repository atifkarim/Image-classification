{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file I am trying to test model file by writing a code only using Numpy. No Keras API has used here. Main part will start by extracting the weight from model file. For loading model.h5 file Keras has used. Preprocessing also has done using some other library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/home/atif/training_by_several_learning_process/flower_photos/train_model_flower/flw_gray_ch_1_ep_100_no_pad_relu_31_dec.h5')\n",
    "#for gray scale\n",
    "def preprocess_img(img):\n",
    "#     Histogram normalization in y\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'/home/atif/training_by_several_learning_process/flower_photos/flower_test_image/'\n",
    "\n",
    "img_path = glob.glob(path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),1,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print(\"\\n\",image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "    \n",
    "    probability = model.predict_proba(X_test)\n",
    "    print(\"probability: \",probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting weight information from  model.h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model = load_model('/home/atif/training_by_several_learning_process/flower_photos/train_model_flower/flw_gray_ch_1_ep_100_no_pad_relu_31_dec.h5')\n",
    "# x_list=[]\n",
    "layer_list =[]\n",
    "# i=0\n",
    "\n",
    "#x_weight=[]\n",
    "# f = open('/home/atif/training_by_several_learning_process/flower_photos/train_model_flower/flw_gray_ch_1_ep_100_no_pad_relu_31_dec.txt', 'w')\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    \n",
    "    layer_list.append(h)\n",
    "#     i=i+1\n",
    "#     print (\"g== \",g,\"\\n\")\n",
    "\n",
    "#     print (\"h== \",h,\"\\n\\n\")\n",
    "    #print(\"type_of g == \",type(g),\"\\n\")\n",
    "    #print(\"type_of h == \",type(h),\"\\n\")\n",
    "    #print(\"h_0_val: \",h[0])\n",
    "    g1=str(g)\n",
    "    h1=str(h)\n",
    "    g_type=str(type(g))\n",
    "    h_type=str(type(h))\n",
    "    \n",
    "#     f.write(\"layer_definition: \"+g1+\"\\n\\n\")\n",
    "#     f.write(\"layer_type: \"+g_type+\"\\n\\n\")\n",
    "#     #f.write(\"\\n\")\n",
    "#     f.write(\"layer_weight: \"+h1+\"\\n\\n\")\n",
    "#     f.write(\"weight_type: \"+h_type+\"\\n\\n\\n\")\n",
    "    #f.write(\"\\n\")\n",
    "    \n",
    "# f.close()\n",
    "# print((layerdic),\"\\n\\n\")\n",
    "#print(layerdic[0][0])\n",
    "layer_name=['conv_layer','flatten_layer','dense_layer']\n",
    "# l=0\n",
    "#print(layer_name[0])\n",
    "\n",
    "# i=0\n",
    "# m=0\n",
    "# for l in layer_name:\n",
    "#     print(l,\"\\n\")\n",
    "#     if i==0:\n",
    "#         print(layerdic[i][0],\"\\n\\n\")\n",
    "#         break\n",
    "        \n",
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose()\n",
    "print(\"conv_kernel: \\n\",conv_kernel,\"\\n\\n\")\n",
    "print(\"conv_kernel shape:\\t\",conv_kernel.shape,\"\\n\\n\")\n",
    "print(\"conv kernel dimension:\\t\",conv_kernel.ndim,\"\\n\\n\")\n",
    "print(\"type_conv_kernel:\",type(conv_kernel),\"\\n\")\n",
    "\n",
    "#conv_kernel_reshape=conv_kernel.reshape(conv_kernel[3],conv_kernel[2],conv_kernel[1],conv_kernel[0])\n",
    "#print(\"re:  \",conv_kernel_reshape.shape)\n",
    "\n",
    "\n",
    "\n",
    "conv_bias=layer_list[0][1]\n",
    "print(\"conv_bias_value: \",conv_bias)\n",
    "print(\"conv_bias ndim: \",conv_bias.ndim,\"\\n\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "# conv_kernel=conv_kernel.transpose()\n",
    "dense_kernel=layer_list[2][0]\n",
    "print(\"dense_kernel: \\n\",dense_kernel,\"\\n\\n\")\n",
    "print(\"dense_kernel shape:\\t\",dense_kernel.shape,\"\\n\\n\")\n",
    "print(\"dense_kernel dimension:\\t\",dense_kernel.ndim,\"\\n\\n\")\n",
    "print(\"type_dense_kernel:\",type(dense_kernel),\"\\n\")\n",
    "print(\"dense_kernel size: \",dense_kernel.size,\"\\n\")\n",
    "# dense_1_transpose=dense__1.transpose()\n",
    "# print(\"dense_1_transpose: \",dense_1_transpose,\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dense_bias=layer_list[2][1]\n",
    "print(\"dense_bias: \",dense_bias)\n",
    "print(\"dense_bias_shape: \",dense_bias.shape)\n",
    "dense_bias=dense_bias.reshape(1,5)\n",
    "print(\"dense_bias_shape: \",dense_bias.shape)\n",
    "# print(dense_2[0])\n",
    "\n",
    "\n",
    "write_conv_kernel=str(conv_kernel)\n",
    "write_conv_bias=str(conv_bias)\n",
    "write_dense_kernel=str(dense_kernel)\n",
    "write_dense_bias=str(dense_bias)\n",
    "\n",
    "\n",
    "# f = open('/home/atif/training_by_several_learning_process/flower_photos/train_model_flower/flw_gray_ch_1_ep_100_no_pad_relu_31_dec_dense_kernel.txt', 'w')\n",
    "\n",
    "# # f.write(\"write_conv_kernel:\\n\\n\"+write_conv_kernel+\"\\n\\n\")\n",
    "\n",
    "# # f.write(\"write_conv_bias:\\n\\n\"+write_conv_bias+\"\\n\\n\")\n",
    "\n",
    "# # f.write(\"write_dense_kernel:\\n\\n\"+write_dense_kernel+\"\\n\\n\")\n",
    "\n",
    "# # f.write(\"write_dense_bias:\\n\\n\"+write_dense_bias+\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here dense_kernel values will be stored in a text file\n",
    "\n",
    "dense_kernel=layer_list[2][0]\n",
    "i_list=[]\n",
    "for i in dense_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i)\n",
    "#     for k in i:\n",
    "# #         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[]\n",
    "# i_list_array=np.array(i_list)\n",
    "# print(i_list_array.shape)\n",
    "# i_list_array=i_list_array.reshape(10580,1)\n",
    "# print(i_list_array.shape)\n",
    "\n",
    "for p in i_list:\n",
    "#     for a in p:\n",
    "#         print(a)\n",
    "    print(p)\n",
    "    ww=str(p)\n",
    "    ww=ww.replace('[','')\n",
    "    ww=ww.replace(']','')\n",
    "#     f=open('/home/atif/demo_mini.txt','a')\n",
    "#     f.write(ww)\n",
    "#     f.write(\"\\n\")\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below at first, I am making conv_kernel suitable for the approach. Like reshaping and storing in an suitable array to get dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"conv_kernel:\\n\",conv_kernel,\"\\n\")\n",
    "print(\"conv_kernel_shape:\",conv_kernel.shape,\"\\tconv_kernel ndim:\",conv_kernel.ndim,\"\\n\")\n",
    "print(\"length of conv_kernel:\",len(conv_kernel),\"\\n\")\n",
    "\n",
    "conv_kernel_reshape=conv_kernel.reshape(1,3,3)\n",
    "print(\"conv_kernel_reshape:\\n\",conv_kernel_reshape,\"\\n\")\n",
    "print(\"conv_kernel_reshape shape:\",conv_kernel_reshape.shape,\"\\tconv_kernel_reshape ndim:\",conv_kernel_reshape.ndim,\"\\n\")\n",
    "print(\"length of conv_kernel_reshape:\",len(conv_kernel_reshape[0]),\"\\n\")\n",
    "\n",
    "convolution_kernel_filter=[]\n",
    "convolution_kernel_filter=np.zeros((1,3,3))\n",
    "convolution_kernel_filter[0,:,:]=np.array(conv_kernel_reshape)\n",
    "print(\"convolution_kernel_filter: \\n\",convolution_kernel_filter,\"\\n\")\n",
    "print(\"convolution_kernel_filter shape:\",convolution_kernel_filter.shape,\"\\tconvolution_kernel_filter ndim:\",convolution_kernel_filter.ndim,\"\\n\")\n",
    "print(\"length of convolution_kernel_filter:\",len(convolution_kernel_filter),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I am reshapingbmy test image for thsi approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_conv = X_test.reshape(IMG_SIZE,IMG_SIZE)\n",
    "print(\"X_test_conv shape: \",X_test_conv.shape,\"\\n\")\n",
    "print(\"length of X_test_conv: \",len(X_test_conv.shape),\"\\n\")\n",
    "print(\"X_test_conv size: \",X_test_conv.size,\"\\n\")\n",
    "print(\"X_test_conv ndim: \",X_test_conv,\"\\n\")\n",
    "plt.imshow(X_test_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In following cell I have added Padding to the input. For my further work to keep simplicity I have not used this but it will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_conv_padded=np.pad(X_test_conv, ((1,1),(1,1)), 'constant')\n",
    "# print(\"X_test_conv_padded size: \",X_test_conv_padded.size,\"\\n\")\n",
    "# plt.imshow(X_test_conv_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for convolution with the convolution filter and then use the created feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "\n",
    "\n",
    "conv_bias=conv_bias\n",
    "print(conv_bias)\n",
    "\n",
    "def conv_(img, conv_filter):\n",
    "    filter_size = conv_filter.shape[1]\n",
    "    print(\"filter_size: \",filter_size)\n",
    "    result = numpy.zeros((img.shape))\n",
    "#     print(\"result: \",result)\n",
    "    #Looping through the image to apply the convolution operation.\n",
    "    for r in numpy.uint16(numpy.arange(filter_size/2.0, \n",
    "                          img.shape[0]-filter_size/2.0+1)):\n",
    "        \n",
    "        for c in numpy.uint16(numpy.arange(filter_size/2.0, \n",
    "                                           img.shape[1]-filter_size/2.0+1)):\n",
    "            \n",
    "            \"\"\"\n",
    "            Getting the current region to get multiplied with the filter.\n",
    "            How to loop through the image and get the region based on \n",
    "            the image and filer sizes is the most tricky part of convolution.\n",
    "            \"\"\"\n",
    "            curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), \n",
    "                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]\n",
    "#             var1=r-numpy.uint16(numpy.floor(filter_size/2.0))\n",
    "#             var2= r+numpy.uint16(numpy.ceil(filter_size/2.0))\n",
    "#             var3= c-numpy.uint16(numpy.floor(filter_size/2.0))\n",
    "#             var4= c+numpy.uint16(numpy.ceil(filter_size/2.0))\n",
    "#             print(\"row from: \",var1,\"\\trow to: \",var2,\"\\n\\ncolumn from: \",var3,\"\\tcolumn to\",var4)\n",
    "        \n",
    "            #Element-wise multipliplication between the current region and the filter.\n",
    "            \n",
    "            curr_result = curr_region * conv_filter\n",
    "            curr_result= curr_result+conv_bias\n",
    "#             print(conv_bias)\n",
    "#             print(curr_result)\n",
    "            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.\n",
    "            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.\n",
    "    #print(curr_region)\n",
    "    #Clipping the outliers of the result matrix.\n",
    "    final_result = result[numpy.uint16(filter_size/2.0):result.shape[0]-numpy.uint16(filter_size/2.0), \n",
    "                          numpy.uint16(filter_size/2.0):result.shape[1]-numpy.uint16(filter_size/2.0)]\n",
    "    return final_result\n",
    "def conv(img, conv_filter):\n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Error: Number of channels in both image and filter must match.\")\n",
    "            sys.exit()\n",
    "    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\n",
    "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')\n",
    "        sys.exit()\n",
    "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
    "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')\n",
    "        sys.exit()\n",
    "\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, \n",
    "                                img.shape[1]-conv_filter.shape[1]+1, \n",
    "                                conv_filter.shape[0]))\n",
    "\n",
    "    # Convolving the image by the filter(s).\n",
    "    for filter_num in range(conv_filter.shape[0]):\n",
    "        print(\"Filter \", filter_num + 1)\n",
    "        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.\n",
    "        \"\"\" \n",
    "        Checking if there are mutliple channels for the single filter.\n",
    "        If so, then each channel will convolve the image.\n",
    "        The result of all convolutions are summed to return a single feature map.\n",
    "        \"\"\"\n",
    "        if len(curr_filter.shape) > 2:\n",
    "            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\n",
    "            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\n",
    "                conv_map = conv_map + conv_(img[:, :, ch_num], \n",
    "                                  curr_filter[:, :, ch_num])\n",
    "        else: # There is just a single channel in the filter.\n",
    "            conv_map = conv_(img, curr_filter)\n",
    "        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\n",
    "    return feature_maps # Returning all feature maps.\n",
    "\n",
    "\n",
    "def relu(feature_map):\n",
    "    #Preparing the output of the ReLU activation function.\n",
    "    relu_out = numpy.zeros(feature_map.shape)\n",
    "    for map_num in range(feature_map.shape[-1]):\n",
    "        for r in numpy.arange(0,feature_map.shape[0]):\n",
    "            for c in numpy.arange(0, feature_map.shape[1]):\n",
    "                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])\n",
    "    return relu_out\n",
    "\n",
    "def softmax_fn(input_array):\n",
    "    e_x=np.exp(input_array-np.max(input_array))\n",
    "    return e_x/e_x.sum(axis=len(e_x.shape)-1)\n",
    "\n",
    "\n",
    "# X_test = X_test.reshape(1,IMG_SIZE,IMG_SIZE)\n",
    "\n",
    "feature=conv(img=X_test_conv,conv_filter=convolution_kernel_filter)\n",
    "soft_max=softmax_fn(feature)\n",
    "relu_out=relu(feature)\n",
    "# # print(img.shape)\n",
    "# print(feature[:,:,0])\n",
    "# print(\"\\n\\n\",feature[:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## following cell is showing the output of 'conv' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature.shape)\n",
    "\n",
    "# x_feature_map=np.flipud(feature[0])\n",
    "transpose_feature_map=feature.transpose()\n",
    "print(\"transpose_feature_map shape: \",transpose_feature_map.shape)\n",
    "plt.imshow(transpose_feature_map[0])\n",
    "print(\"transpose_feature_map: \\n\",transpose_feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## following cell works with relu. if you want to apply relu on feature map then execute it. for this you have to also change in the called model in the training phase and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"relu_out shape: \",relu_out.shape)\n",
    "relu_out_transpose=relu_out.transpose()\n",
    "print(\"relu_out_transpose shape: \",relu_out_transpose.shape)\n",
    "plt.imshow(relu_out_transpose[0])\n",
    "print(\"relu_out_transpose:\\n\",relu_out_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cell I have done matrix_multiplication between relu output and dense_kernel. Finally added dense_bias value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_relu_out_transpose=relu_out_transpose.reshape(1,1*46*46)  #if you don't do padd on input image please make it 46*46. how 46 came? \n",
    "                                                                                    #the formula of output size.\n",
    "print(\"flatten_relu_out_transpose shape: \",flatten_relu_out_transpose.shape)\n",
    "\n",
    "print(\"dense_kernel shape: \",dense_kernel.shape,\"\\n\")\n",
    "\n",
    "matmul_flatt_rel_dense_kernel=np.matmul(flatten_relu_out_transpose,dense_kernel)\n",
    "print(\"matmul_soft_dense_kernel shape\",matmul_flatt_rel_dense_kernel.shape,\"\\n\")\n",
    "print(\"matmul_soft_dense_kernel: \",matmul_flatt_rel_dense_kernel,\"\\n\")\n",
    "\n",
    "dense_bias_array=np.array(dense_bias)\n",
    "dense_bias_array=dense_bias_array.reshape(1,5)\n",
    "print(\"dense_bias_array: \",dense_bias_array,\"\\n\")\n",
    "\n",
    "add_matmul_flatt_rel_dense_kernel_and_dense_bias_array=matmul_flatt_rel_dense_kernel+dense_bias_array\n",
    "print(\"value add_matmul_flatt_rel_dense_kernel_and_dense2_array:\\n\",add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, I have applied softmax to the output and then calculated the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_fn(input_array):\n",
    "    e_x=np.exp(input_array-np.max(input_array))\n",
    "    return e_x/e_x.sum(axis=len(e_x.shape)-1)\n",
    "\n",
    "op= softmax_fn(add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "print(\"output of FC layer: \",op,\"\\n\")\n",
    "########################\n",
    "# Folowing code for finding class##\n",
    "########################\n",
    "m=0\n",
    "k=0\n",
    "# op=[[0.17095664, 0.24349895, 0.172376,   0.19243606, 0.62073235]]\n",
    "# op=np.array(op)\n",
    "# print(op.shape)\n",
    "# print(type(op))\n",
    "\n",
    "for h in op:\n",
    "    \n",
    "    for index,j in enumerate(h):\n",
    "    \n",
    "        o=j\n",
    "        #print(o)\n",
    "        if o>m:\n",
    "            m=o\n",
    "            print(m)\n",
    "            k=index\n",
    "        else:\n",
    "            pass\n",
    "print('class:',k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
