{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file I am trying to test trained model/ classify image by writing a code only using Numpy. No Keras API has used here. Main part will start by extracting the weight from model file. For loading model.h5 file Keras has used. Preprocessing also has done using some other scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file will work for multi convolution filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 9 #Used class for the training\n",
    "IMG_SIZE = 48 #required size. This size has also maintained during training. User defined value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract weight from trained model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/home/atif/image_classification_c++/multi_filter_cpp/traffic_2_filter_no_pad_gray_ep_100_for_cpp.h5')\n",
    "#model = load_model('/home/atif/traffic_model_11_dec_1_filter.h5')\n",
    "layer_list =[]\n",
    "# f = open('/home/atif/path_for_storing_all_layer_info.txt', 'w') #uncomment it if you want to store all layer info at a time.\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    \n",
    "    layer_list.append(h)\n",
    "#     print (\"g== \",g,\"\\n\") #for printing layer name and verbal info\n",
    "\n",
    "#     print (\"h== \",h,\"\\n\\n\") # for printing layer numeric value, eg: weight, bias value\n",
    "#     print(\"type_of g == \",type(g),\"\\n\")\n",
    "#     print(\"type_of h == \",type(h),\"\\n\")\n",
    "\n",
    "# below lines till f.close() used for writing in text file. To do this you have to uncomment the above line started with f.open() also.\n",
    "\n",
    "#     g1=str(g) # declaring a string variable g1 to store the info of g\n",
    "#     h1=str(h) #declaring a string variable h1 to store the info of h\n",
    "#     g_type=str(type(g)) #declaring a string variable g1 to store the type of g\n",
    "#     h_type=str(type(h)) #declaring a string variable h1 to store the type of h\n",
    "    \n",
    "#     f.write(\"layer_definition: \"+g1+\"\\n\\n\")\n",
    "#     f.write(\"layer_type: \"+g_type+\"\\n\\n\")\n",
    "#     #f.write(\"\\n\")\n",
    "#     f.write(\"layer_weight: \"+h1+\"\\n\\n\")\n",
    "#     f.write(\"weight_type: \"+h_type+\"\\n\\n\\n\")\n",
    "#     f.write(\"\\n\")\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display extracted weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose()\n",
    "#print(\"conv_kernel: \\n\",conv_kernel,\"\\n\\n\")\n",
    "#print(\"conv_kernel shape:\\t\",conv_kernel.shape,\"\\n\\n\")\n",
    "#print(\"conv kernel dimension:\\t\",conv_kernel.ndim,\"\\n\\n\")\n",
    "#print(\"type_conv_kernel:\",type(conv_kernel),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "conv_bias=layer_list[0][1]\n",
    "#print(\"conv_bias_value: \",conv_bias)\n",
    "#print(\"conv_bias ndim: \",conv_bias.ndim,\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "dense_kernel=layer_list[2][0]\n",
    "#print(\"dense_kernel: \\n\",dense_kernel,\"\\n\\n\")\n",
    "#print(\"dense_kernel shape:\\t\",dense_kernel.shape,\"\\n\\n\")\n",
    "#print(\"dense_kernel dimension:\\t\",dense_kernel.ndim,\"\\n\\n\")\n",
    "#print(\"type_dense_kernel:\",type(dense_kernel),\"\\n\")\n",
    "#print(\"dense_kernel size: \",dense_kernel.size,\"\\n\")\n",
    "# dense_1_transpose=dense__1.transpose()\n",
    "# print(\"dense_1_transpose: \",dense_1_transpose,\"\\n\\n\")\n",
    "\n",
    "\n",
    "dense_bias=layer_list[2][1]\n",
    "#print(\"dense_bias: \",dense_bias)\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)\n",
    "dense_bias=dense_bias.reshape(1,9) # here chenge 5 to the number of your used class\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing convolution kernel weight in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose() # This has made to print it like a Matrix form. \n",
    "i_list=[]\n",
    "for i in conv_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i)\n",
    "#     for k in i:\n",
    "#         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[]\n",
    "i_list_array=np.array(i_list)\n",
    "# print(i_list_array.shape)\n",
    "# i_list_array=i_list_array.reshape(2,3,3)\n",
    "# print(i_list_array.ndim)\n",
    "\n",
    "for p in i_list_array:\n",
    "#     for a in p:\n",
    "#         print(a)\n",
    "#    print(p)\n",
    "    ww=str(p)\n",
    "    ww=ww.replace('[','')\n",
    "    ww=ww.replace(']','')\n",
    "    #f=open('/home/atif/conv_k_spy.txt','a') #uncomment from here till f.close() if you want to save text file\n",
    "    #f.write(ww)\n",
    "    #f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing convolution kernel bias value in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bias=layer_list[0][1]\n",
    "conv_bias_list=[]\n",
    "for i in conv_bias:\n",
    "    conv_bias_list.append(i)\n",
    "\n",
    "conv_bias_array=[]\n",
    "conv_bias_array=np.array(conv_bias_list)\n",
    "#print(conv_bias_array)\n",
    "#np.savetxt('/home/atif/conv_b_spy.txt', conv_bias_array, fmt='%1.8e',delimiter=' ')\n",
    "\n",
    "#for x in conv_bias_array:\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Dense kernel weight in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_kernel=layer_list[2][0]\n",
    "i_list=[] #declare a list to store the weight of dense kernel\n",
    "for i in dense_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i) #appended it in the declared list\n",
    "#     for k in i:\n",
    "# #         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[] #declared an array\n",
    "i_list_array=np.array(i_list) # store the value of list in the array\n",
    "#print(i_list_array)\n",
    "#np.savetxt('/home/atif/dense_k_spy.txt', i_list_array, fmt='%1.8e',delimiter=' ') #writing on a text file from array\n",
    "\n",
    "# %.8f #you can use it to get float value\n",
    "# fmt='%1.8e' #add this above line after i_list_aray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Dense kernel bias value in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_bias=layer_list[2][1]\n",
    "dense_bias_list=[]\n",
    "for i in dense_bias:\n",
    "    dense_bias_list.append(i)\n",
    "\n",
    "dense_bias_array=[]\n",
    "dense_bias_array=np.array(dense_bias_list)\n",
    "#print(dense_bias_array)\n",
    "#np.savetxt('/home/atif/dense_b_spy.txt', dense_bias_array, fmt='%1.8e',delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping convolution kernel for further process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"conv_kernel:\\n\",conv_kernel,\"\\n\")\n",
    "#print(\"conv_kernel_shape:\",conv_kernel.shape,\"\\tconv_kernel ndim:\",conv_kernel.ndim,\"\\n\")\n",
    "#print(\"length of conv_kernel:\",len(conv_kernel),\"\\n\")\n",
    "\n",
    "conv_kernel_reshape=conv_kernel.reshape(2,3,3) # 2 for 2 filter. change it according to your filter number\n",
    "#print(\"conv_kernel_reshape:\\n\",conv_kernel_reshape,\"\\n\")\n",
    "#print(\"conv_kernel_reshape shape:\",conv_kernel_reshape.shape,\"\\tconv_kernel_reshape ndim:\",conv_kernel_reshape.ndim,\"\\n\")\n",
    "#print(\"length of conv_kernel_reshape:\",len(conv_kernel_reshape[0]),\"\\n\")\n",
    "\n",
    "convolution_kernel_filter=[]\n",
    "convolution_kernel_filter=np.zeros((2,3,3)) # 2 for 2 filter. change it according to your filter number\n",
    "convolution_kernel_filter[:,:,:]=np.array(conv_kernel_reshape)\n",
    "#print(\"convolution_kernel_filter: \\n\",convolution_kernel_filter,\"\\n\")\n",
    "#print(\"convolution_kernel_filter shape:\",convolution_kernel_filter.shape,\"\\tconvolution_kernel_filter ndim:\",convolution_kernel_filter.ndim,\"\\n\")\n",
    "#print(\"length of convolution_kernel_filter:\",len(convolution_kernel_filter),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for Classification\n",
    "## At first processing image, Convolution and apply Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hey i am the loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/50_speed.ppm\n",
      "\n",
      "conv function start to work\n",
      "Filter  1\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is:  1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "Filter  2\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is:  1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "\n",
      "feature shape: \n",
      " (46, 46, 2)\n",
      "\n",
      "transpose_feature_map shape:  (2, 46, 46)\n",
      "\n",
      "transpose_feature_map: \n",
      " [[[12.83524381 12.89827702 12.69299064 ... 12.48510745 12.42706233\n",
      "   12.41527678]\n",
      "  [12.46366136 12.43829145 12.50764527 ... 12.50014892 12.50891834\n",
      "   12.50337312]\n",
      "  [12.47156399 12.34354419 12.42108959 ... 12.50072963 12.58194619\n",
      "   12.54422294]\n",
      "  ...\n",
      "  [12.70146209 12.75421606 13.07856518 ... 12.67075972 12.47462193\n",
      "   12.4677353 ]\n",
      "  [12.24212468 12.24812207 13.12368574 ... 13.61974367 12.62934196\n",
      "   12.53553577]\n",
      "  [12.33776982 11.73183996 11.93700706 ... 14.65144725 13.05182385\n",
      "   12.65983353]]\n",
      "\n",
      " [[11.33055117 11.41377948 11.64988406 ... 11.9309422  11.93915027\n",
      "   11.90745106]\n",
      "  [11.54857532 11.67623328 11.73364106 ... 11.90052573 11.88152265\n",
      "   11.87391036]\n",
      "  [11.68756531 11.79146852 11.73311337 ... 11.84990513 11.82562954\n",
      "   11.84122817]\n",
      "  ...\n",
      "  [11.51518193 11.35850051 10.90092791 ... 11.80302798 11.88810333\n",
      "   11.87001895]\n",
      "  [11.65504977 11.16610811 10.12630836 ... 11.38425536 11.78604394\n",
      "   11.83075044]\n",
      "  [11.68610412 11.14748383 10.07281719 ... 10.9968272  11.53530842\n",
      "   11.63100657]]]\n",
      "\n",
      "relu_out shape:  (46, 46, 2)\n",
      "\n",
      "relu_out_transpose shape:  (2, 46, 46)\n",
      "\n",
      "relu_out_transpose:\n",
      " [[[12.83524381 12.89827702 12.69299064 ... 12.48510745 12.42706233\n",
      "   12.41527678]\n",
      "  [12.46366136 12.43829145 12.50764527 ... 12.50014892 12.50891834\n",
      "   12.50337312]\n",
      "  [12.47156399 12.34354419 12.42108959 ... 12.50072963 12.58194619\n",
      "   12.54422294]\n",
      "  ...\n",
      "  [12.70146209 12.75421606 13.07856518 ... 12.67075972 12.47462193\n",
      "   12.4677353 ]\n",
      "  [12.24212468 12.24812207 13.12368574 ... 13.61974367 12.62934196\n",
      "   12.53553577]\n",
      "  [12.33776982 11.73183996 11.93700706 ... 14.65144725 13.05182385\n",
      "   12.65983353]]\n",
      "\n",
      " [[11.33055117 11.41377948 11.64988406 ... 11.9309422  11.93915027\n",
      "   11.90745106]\n",
      "  [11.54857532 11.67623328 11.73364106 ... 11.90052573 11.88152265\n",
      "   11.87391036]\n",
      "  [11.68756531 11.79146852 11.73311337 ... 11.84990513 11.82562954\n",
      "   11.84122817]\n",
      "  ...\n",
      "  [11.51518193 11.35850051 10.90092791 ... 11.80302798 11.88810333\n",
      "   11.87001895]\n",
      "  [11.65504977 11.16610811 10.12630836 ... 11.38425536 11.78604394\n",
      "   11.83075044]\n",
      "  [11.68610412 11.14748383 10.07281719 ... 10.9968272  11.53530842\n",
      "   11.63100657]]]\n",
      "\n",
      "flatten_relu_out_transpose shape: \n",
      " (1, 4232)\n",
      "\n",
      "dense_kernel shape: \n",
      " (4232, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel shape: \n",
      " (1, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel: \n",
      " [[-229.02971039  -13.19883098   29.48237061   63.30143727   96.92439144\n",
      "    51.01483828  -19.97896909  -56.74490221   -2.46131332]] \n",
      "\n",
      "\n",
      "dense_bias_array: \n",
      " [[-0.01253249  0.19295532  0.06694246  0.18706687 -0.24281958  0.13072969\n",
      "  -0.02468821 -0.22385639 -0.07379571]] \n",
      "\n",
      "\n",
      "value add_matmul_flatt_rel_dense_kernel_and_dense2_array: \n",
      " [[-229.04224288  -13.00587566   29.54931307   63.48850414   96.68157187\n",
      "    51.14556797  -20.0036573   -56.9687586    -2.53510902]]\n",
      "output of FC layer:  [[3.46692648e-142 2.30858997e-048 6.99568826e-030 3.84090751e-015\n",
      "  1.00000000e+000 1.67480705e-020 2.10983676e-051 1.86427226e-067\n",
      "  8.14222271e-044]] \n",
      "\n",
      "3.466926483846102e-142\n",
      "2.3085899666969084e-48\n",
      "6.995688263318184e-30\n",
      "3.8409075116573936e-15\n",
      "0.9999999999999962\n",
      "class: 4\n",
      "\n",
      "hey i am the loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/20_speed.ppm\n",
      "\n",
      "conv function start to work\n",
      "Filter  1\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "Filter  2\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is:  1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "\n",
      "feature shape: \n",
      " (46, 46, 2)\n",
      "\n",
      "transpose_feature_map shape:  (2, 46, 46)\n",
      "\n",
      "transpose_feature_map: \n",
      " [[[12.85469331 12.80351535 12.50152084 ... 13.70460416 13.87819388\n",
      "   13.98133088]\n",
      "  [12.9262991  12.94049627 12.93794253 ... 13.62652226 13.61762885\n",
      "   13.47864375]\n",
      "  [13.21165088 13.12513496 13.082702   ... 11.82588186 11.66371481\n",
      "   11.35648115]\n",
      "  ...\n",
      "  [12.7957152  12.53230847 12.58950414 ... 13.11564023 12.91095333\n",
      "   12.79097532]\n",
      "  [12.83226201 12.53837633 12.51520163 ... 12.90808282 12.76317884\n",
      "   12.79691429]\n",
      "  [12.92350713 12.6769748  12.59621988 ... 12.50625379 12.48074281\n",
      "   12.69106322]]\n",
      "\n",
      " [[10.78976617 10.76882153 10.73857001 ... 10.10797066 10.03532384\n",
      "    9.96305355]\n",
      "  [10.73409182 10.73859663 10.75586734 ... 10.0256064  10.12496212\n",
      "   10.23356547]\n",
      "  [10.53101051 10.5886996  10.59782066 ... 11.07753895 11.19629646\n",
      "   11.31611519]\n",
      "  ...\n",
      "  [11.39914001 11.33381494 11.1529845  ... 10.47077602 10.67787948\n",
      "   10.83030482]\n",
      "  [11.37458592 11.33248487 11.16442935 ... 10.73142198 10.88833237\n",
      "   10.93076736]\n",
      "  [11.28395105 11.28400872 11.14838435 ... 11.07071923 11.10912455\n",
      "   11.03115898]]]\n",
      "\n",
      "relu_out shape:  (46, 46, 2)\n",
      "\n",
      "relu_out_transpose shape:  (2, 46, 46)\n",
      "\n",
      "relu_out_transpose:\n",
      " [[[12.85469331 12.80351535 12.50152084 ... 13.70460416 13.87819388\n",
      "   13.98133088]\n",
      "  [12.9262991  12.94049627 12.93794253 ... 13.62652226 13.61762885\n",
      "   13.47864375]\n",
      "  [13.21165088 13.12513496 13.082702   ... 11.82588186 11.66371481\n",
      "   11.35648115]\n",
      "  ...\n",
      "  [12.7957152  12.53230847 12.58950414 ... 13.11564023 12.91095333\n",
      "   12.79097532]\n",
      "  [12.83226201 12.53837633 12.51520163 ... 12.90808282 12.76317884\n",
      "   12.79691429]\n",
      "  [12.92350713 12.6769748  12.59621988 ... 12.50625379 12.48074281\n",
      "   12.69106322]]\n",
      "\n",
      " [[10.78976617 10.76882153 10.73857001 ... 10.10797066 10.03532384\n",
      "    9.96305355]\n",
      "  [10.73409182 10.73859663 10.75586734 ... 10.0256064  10.12496212\n",
      "   10.23356547]\n",
      "  [10.53101051 10.5886996  10.59782066 ... 11.07753895 11.19629646\n",
      "   11.31611519]\n",
      "  ...\n",
      "  [11.39914001 11.33381494 11.1529845  ... 10.47077602 10.67787948\n",
      "   10.83030482]\n",
      "  [11.37458592 11.33248487 11.16442935 ... 10.73142198 10.88833237\n",
      "   10.93076736]\n",
      "  [11.28395105 11.28400872 11.14838435 ... 11.07071923 11.10912455\n",
      "   11.03115898]]]\n",
      "\n",
      "flatten_relu_out_transpose shape: \n",
      " (1, 4232)\n",
      "\n",
      "dense_kernel shape: \n",
      " (4232, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel shape: \n",
      " (1, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel: \n",
      " [[-230.1775077     7.33949351   41.34406486   72.43913189   75.88097047\n",
      "    26.71622941  -11.37964873  -55.62857178    1.3119164 ]] \n",
      "\n",
      "\n",
      "dense_bias_array: \n",
      " [[-0.01253249  0.19295532  0.06694246  0.18706687 -0.24281958  0.13072969\n",
      "  -0.02468821 -0.22385639 -0.07379571]] \n",
      "\n",
      "\n",
      "value add_matmul_flatt_rel_dense_kernel_and_dense2_array: \n",
      " [[-230.19004019    7.53244883   41.41100732   72.62619876   75.6381509\n",
      "    26.8469591   -11.40433694  -55.85242817    1.23812069]]\n",
      "output of FC layer:  [[1.44426791e-133 2.51891183e-030 1.30161928e-015 4.68888268e-002\n",
      "  9.53111173e-001 6.15741181e-022 1.50338912e-038 7.47326963e-058\n",
      "  4.65179953e-033]] \n",
      "\n",
      "1.4442679059689178e-133\n",
      "2.518911831904704e-30\n",
      "1.3016192821246158e-15\n",
      "0.046888826826912006\n",
      "0.9531111731730867\n",
      "class: 4\n",
      "\n",
      "hey i am the loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/stop.ppm\n",
      "\n",
      "conv function start to work\n",
      "Filter  1\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is:  1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "Filter  2\n",
      "\n",
      "Go to conv_ function \n",
      "\n",
      "conv_ function start to work\n",
      "\n",
      "filter_size:  3\n",
      "img shape:  (48, 48)\n",
      "i am the conv_bias:  0.014436238\n",
      "now x is:  0.014436238\n",
      "i am the conv_bias:  1.3674825\n",
      "now x is:  1.3674825\n",
      "\n",
      "conv_ function finish\n",
      "\n",
      "\n",
      "feature shape: \n",
      " (46, 46, 2)\n",
      "\n",
      "transpose_feature_map shape:  (2, 46, 46)\n",
      "\n",
      "transpose_feature_map: \n",
      " [[[14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  ...\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]]\n",
      "\n",
      " [[ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  ...\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]]]\n",
      "\n",
      "relu_out shape:  (46, 46, 2)\n",
      "\n",
      "relu_out_transpose shape:  (2, 46, 46)\n",
      "\n",
      "relu_out_transpose:\n",
      " [[[14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  ...\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]\n",
      "  [14.42878222 14.42878222 14.42878222 ... 14.42878222 14.42878222\n",
      "   14.42878222]]\n",
      "\n",
      " [[ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  ...\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]\n",
      "  [ 6.66914304  6.66914304  6.66914304 ...  6.66914304  6.66914304\n",
      "    6.66914304]]]\n",
      "\n",
      "flatten_relu_out_transpose shape: \n",
      " (1, 4232)\n",
      "\n",
      "dense_kernel shape: \n",
      " (4232, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel shape: \n",
      " (1, 9) \n",
      "\n",
      "\n",
      "matmul_soft_dense_kernel: \n",
      " [[-211.23714291  -21.55578826   34.19339128  105.10210933   54.84653554\n",
      "    18.33032707  -20.47803685  -26.59364727  -14.34098583]] \n",
      "\n",
      "\n",
      "dense_bias_array: \n",
      " [[-0.01253249  0.19295532  0.06694246  0.18706687 -0.24281958  0.13072969\n",
      "  -0.02468821 -0.22385639 -0.07379571]] \n",
      "\n",
      "\n",
      "value add_matmul_flatt_rel_dense_kernel_and_dense2_array: \n",
      " [[-211.2496754   -21.36283295   34.26033374  105.2891762    54.60371596\n",
      "    18.46105676  -20.50272505  -26.81750365  -14.41478153]]\n",
      "output of FC layer:  [[3.38005245e-138 9.90219113e-056 1.42090703e-031 1.00000000e+000\n",
      "  9.71816579e-023 1.95446030e-038 2.34029938e-055 4.23445884e-058\n",
      "  1.03093597e-052]] \n",
      "\n",
      "3.380052453539173e-138\n",
      "9.902191131949987e-56\n",
      "1.4209070255903226e-31\n",
      "1.0\n",
      "class: 3\n"
     ]
    }
   ],
   "source": [
    "def preprocess_img(img):\n",
    "#     uncomment following 5 lines for rgb testing and comment out the rgb2gray line\n",
    "#     Histogram normalization in y\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "    img = rgb2gray(img) #rgb to gray conversion\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def conv_(img, conv_filter):\n",
    "#     print(\"\\nconv_ function start to work\\n\")\n",
    "    filter_size = conv_filter.shape[1] #output is 3\n",
    "#     print(\"filter_size: \",filter_size)\n",
    "#     print(\"img shape: \",img.shape)\n",
    "    result = np.zeros((img.shape))\n",
    "    #Looping through the image to apply the convolution operation.\n",
    "    \n",
    "    for x in conv_bias_array:  # to get the value of convolution bias\n",
    "#         print(\"i am the conv_bias: \",x)\n",
    "        \n",
    "        for r in np.uint16(np.arange(filter_size/2.0,img.shape[0]-filter_size/2.0+1)):\n",
    "        \n",
    "            for c in np.uint16(np.arange(filter_size/2.0,img.shape[1]-filter_size/2.0+1)):\n",
    "            \n",
    "                curr_region = img[r-np.uint16(np.floor(filter_size/2.0)):r+np.uint16(np.ceil(filter_size/2.0)), c-np.uint16(np.floor(filter_size/2.0)):c+np.uint16(np.ceil(filter_size/2.0))]\n",
    "        \n",
    "                #Element-wise multipliplication between the current region and the filter.\n",
    "            \n",
    "                curr_result = curr_region * conv_filter\n",
    "#             print(\"curr_result: \",curr_result)\n",
    "                curr_result= curr_result+x\n",
    "                \n",
    "#             print(\"conv_bias: \",conv_bias_new)\n",
    "#                 print(\"new curr res: \",curr_result)\n",
    "                conv_sum = np.sum(curr_result) #Summing the result of multiplication.\n",
    "                result[r, c] = conv_sum#Saving the summation in the convolution layer feature map.\n",
    "#             print(\"conv_sum_shape: \",conv_sum.shape)\n",
    "#         print(\"now x is: \",x)\n",
    "        #print(curr_region)\n",
    "    #Clipping the outliers of the result matrix.\n",
    "    final_result = result[np.uint16(filter_size/2.0):result.shape[0]-np.uint16(filter_size/2.0),np.uint16(filter_size/2.0):result.shape[1]-np.uint16(filter_size/2.0)]\n",
    "#     print(\"\\nconv_ function finish\\n\")\n",
    "    return final_result\n",
    "\n",
    "\n",
    "\n",
    "def conv(img, conv_filter):\n",
    "#     print(\"\\nconv function start to work\")\n",
    "    \n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Error: Number of channels in both image and filter must match.\")\n",
    "            sys.exit()\n",
    "    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\n",
    "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')\n",
    "        sys.exit()\n",
    "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
    "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')\n",
    "        sys.exit()\n",
    "\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    feature_maps = np.zeros((img.shape[0]-conv_filter.shape[1]+1, img.shape[1]-conv_filter.shape[1]+1, conv_filter.shape[0]))\n",
    "\n",
    "    # Convolving the image by the filter(s).\n",
    "    \n",
    "    for filter_num in range(conv_filter.shape[0]):\n",
    "#         print(\"filter num: \",filter_num)\n",
    "        print(\"Filter \", filter_num + 1)\n",
    "        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.\n",
    "#         print(curr_filter)\n",
    "        #print(\"curr_fiter_shape: \",curr_filter.shape)\n",
    "#         print(\"length of curr_fiter_shape: \",len(curr_filter.shape))\n",
    "\n",
    "\n",
    "        if len(curr_filter.shape) > 2:\n",
    "            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\n",
    "            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\n",
    "                conv_map = conv_map + conv_(img[:, :, ch_num], \n",
    "                                  curr_filter[:, :, ch_num])\n",
    "        else: # There is just a single channel in the filter.\n",
    "#             print(\"\\nGo to conv_ function \")\n",
    "            conv_map = conv_(img, curr_filter)\n",
    "            \n",
    "        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\n",
    "#         print(\"feature_maps from conv_map: \",feature_maps)\n",
    "    return feature_maps # Returning all feature maps.\n",
    "\n",
    "\n",
    "def relu(feature_map):\n",
    "    #Preparing the output of the ReLU activation function.\n",
    "    relu_out = np.zeros(feature_map.shape)\n",
    "    for map_num in range(feature_map.shape[-1]):\n",
    "        for r in np.arange(0,feature_map.shape[0]):\n",
    "            for c in np.arange(0, feature_map.shape[1]):\n",
    "                relu_out[r, c, map_num] = np.max([feature_map[r, c, map_num], 0])\n",
    "    return relu_out\n",
    "\n",
    "\n",
    "\n",
    "path = r'/home/atif/image_classification_c++/multi_filter_cpp/test_image/'\n",
    "\n",
    "img_path = glob.glob(path+ '/*.ppm')\n",
    "for image in img_path:\n",
    "    print(\"\\nName of loaded image: \",image)\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    feature=conv(img=X_test,conv_filter=convolution_kernel_filter) #conv function calling\n",
    "    relu_out=relu(feature) # relu function calling\n",
    "    \n",
    "    # output of feature map / conv function\n",
    "\n",
    "#     print(\"\\nfeature shape: \\n\",feature.shape)\n",
    "\n",
    "    # x_feature_map=np.flipud(feature[0])\n",
    "    transpose_feature_map=feature.transpose()\n",
    "#     print(\"\\ntranspose_feature_map shape: \",transpose_feature_map.shape)\n",
    "#     plt.imshow(transpose_feature_map[0])\n",
    "#     print(\"\\ntranspose_feature_map: \\n\",transpose_feature_map)\n",
    "    \n",
    "#     print(\"\\nrelu_out shape: \",relu_out.shape)\n",
    "    relu_out_transpose=relu_out.transpose()\n",
    "#     print(\"\\nrelu_out_transpose shape: \",relu_out_transpose.shape)\n",
    "#     plt.imshow(relu_out_transpose[0])\n",
    "#     print(\"\\nrelu_out_transpose:\\n\",relu_out_transpose)\n",
    "    \n",
    "# Matrix Multiplication with Dense kernel weight and Convolved Image\n",
    "\n",
    "    flatten_relu_out_transpose=relu_out_transpose.reshape(1,2*46*46)  #if you don't do padd on input image please make it 46*46. how 46 came? \n",
    "                                                                                    #the formula of output size. and 2 for 2 feature map. Here 2 filter so 2 featue map\n",
    "#     print(\"\\nflatten_relu_out_transpose shape: \\n\",flatten_relu_out_transpose.shape)\n",
    "#     print(\"\\ndense_kernel shape: \\n\",dense_kernel.shape,\"\\n\")\n",
    "    matmul_flatt_rel_dense_kernel=np.matmul(flatten_relu_out_transpose,dense_kernel)\n",
    "#     print(\"\\nmatmul_soft_dense_kernel shape: \\n\",matmul_flatt_rel_dense_kernel.shape,\"\\n\")\n",
    "#     print(\"\\nmatmul_soft_dense_kernel: \\n\",matmul_flatt_rel_dense_kernel,\"\\n\")\n",
    "\n",
    "    dense_bias_array=np.array(dense_bias)\n",
    "    dense_bias_array=dense_bias_array.reshape(1,9) # 9 for 9 class\n",
    "#     print(\"\\ndense_bias_array: \\n\",dense_bias_array,\"\\n\")\n",
    "\n",
    "    add_matmul_flatt_rel_dense_kernel_and_dense_bias_array=matmul_flatt_rel_dense_kernel+dense_bias_array\n",
    "#     print(\"\\nvalue add_matmul_flatt_rel_dense_kernel_and_dense2_array: \\n\",add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "    \n",
    "    def softmax_fn(input_array):\n",
    "        e_x=np.exp(input_array-np.max(input_array))\n",
    "        return e_x/e_x.sum(axis=len(e_x.shape)-1)\n",
    "\n",
    "    op= softmax_fn(add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "#     print(\"output of FC layer: \",op,\"\\n\")\n",
    "    \n",
    "#   Show class of loaded image\n",
    "\n",
    "    m=0\n",
    "    k=0\n",
    "    # op=[[0.17095664, 0.24349895, 0.172376,   0.19243606, 0.62073235]]\n",
    "    # op=np.array(op)\n",
    "    # print(op.shape)\n",
    "    # print(type(op))\n",
    "\n",
    "    for h in op:\n",
    "        for index,j in enumerate(h):\n",
    "            o=j\n",
    "            #print(o)\n",
    "            if o>m:\n",
    "                m=o\n",
    "                print(m)\n",
    "                k=index\n",
    "            else:\n",
    "                pass\n",
    "    print('class:',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
