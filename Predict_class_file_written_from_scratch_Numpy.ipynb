{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file I am trying to test trained model/ classify image by writing a code only using Numpy. No Keras API has used here. Main part will start by extracting the weight from model file. For loading model.h5 file Keras has used. Preprocessing also has done using some other scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file will work for multi convolution filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 9 #Used class for the training\n",
    "IMG_SIZE = 48 #required size. This size has also maintained during training. User defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "#from skimage import io, color, exposure, transform\n",
    "#from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os, json\n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "with open('variable_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "NUM_CLASSES = config['DEFAULT']['num_class']\n",
    "IMG_SIZE = config['DEFAULT']['img_size']\n",
    "number_filter = config['DEFAULT']['number_filter']\n",
    "filter_size = config['DEFAULT']['filter_size']\n",
    "img_depth = config['DEFAULT']['img_depth']\n",
    "img_type = config['DEFAULT']['img_type']\n",
    "epochs = config['DEFAULT']['epochs']\n",
    "batch_size = config['DEFAULT']['batch_size']\n",
    "train_image_path = config['DEFAULT']['train_image_path']\n",
    "test_image_path = config['DEFAULT']['test_image_path']\n",
    "learning_model_path = config['DEFAULT']['learning_model_path']\n",
    "validation_split = config['DEFAULT']['validation_split']\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# NUM_CLASSES = 9 #Used class for the training\n",
    "# IMG_SIZE = 8 #required size. This size has also maintained during training. User defined value\n",
    "# number_filter=1\n",
    "total_time=0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/item_venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /home/atif/item_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "g==  {'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_constraint': None, 'name': 'conv2d_1', 'trainable': True, 'bias_initializer': {'config': {}, 'class_name': 'Zeros'}, 'strides': (1, 1), 'activation': 'relu', 'kernel_size': (3, 3), 'filters': 5, 'dtype': 'float32', 'padding': 'valid', 'data_format': 'channels_first', 'activity_regularizer': None, 'kernel_initializer': {'config': {'seed': None, 'mode': 'fan_avg', 'distribution': 'uniform', 'scale': 1.0}, 'class_name': 'VarianceScaling'}, 'use_bias': True, 'batch_input_shape': (None, 1, 48, 48), 'kernel_constraint': None, 'bias_regularizer': None} \n",
      "\n",
      "h==  [array([[[[-0.67074907, -0.26519078, -1.5925051 ,  0.0586549 ,\n",
      "           0.43710935]],\n",
      "\n",
      "        [[-0.7462511 , -0.20440044, -0.5556934 , -0.09233072,\n",
      "           1.566656  ]],\n",
      "\n",
      "        [[-0.36227798,  0.01618635, -0.18157953,  0.238696  ,\n",
      "           1.5616229 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.59329855, -0.19100626, -0.5391095 ,  0.04417358,\n",
      "          -0.6779395 ]],\n",
      "\n",
      "        [[-0.3903124 , -0.29235226,  0.7204196 , -0.32553932,\n",
      "           0.9854658 ]],\n",
      "\n",
      "        [[-0.09837703, -0.33096606,  1.145218  , -0.09672035,\n",
      "           0.89573854]]],\n",
      "\n",
      "\n",
      "       [[[-0.53431404,  0.2422876 , -0.56155765, -0.21519895,\n",
      "          -1.9064794 ]],\n",
      "\n",
      "        [[ 0.06319907,  0.07251699,  1.0512314 ,  0.0979021 ,\n",
      "          -0.7540373 ]],\n",
      "\n",
      "        [[ 0.5340042 ,  0.04459456,  1.6162105 ,  0.1477777 ,\n",
      "          -0.4884904 ]]]], dtype=float32), array([ 0.63377595, -0.01135568, -0.02604145, -0.11364901, -0.0088685 ],\n",
      "      dtype=float32)] \n",
      "\n",
      "\n",
      "type_of g ==  <class 'dict'> \n",
      "\n",
      "type_of h ==  <class 'list'> \n",
      "\n",
      "g==  {'trainable': True, 'name': 'flatten_1'} \n",
      "\n",
      "h==  [] \n",
      "\n",
      "\n",
      "type_of g ==  <class 'dict'> \n",
      "\n",
      "type_of h ==  <class 'list'> \n",
      "\n",
      "g==  {'kernel_regularizer': None, 'activation': 'softmax', 'name': 'dense_1', 'units': 9, 'bias_constraint': None, 'bias_initializer': {'config': {}, 'class_name': 'Zeros'}, 'trainable': True, 'activity_regularizer': None, 'kernel_initializer': {'config': {'seed': None, 'mode': 'fan_avg', 'distribution': 'uniform', 'scale': 1.0}, 'class_name': 'VarianceScaling'}, 'kernel_constraint': None, 'bias_regularizer': None, 'use_bias': True} \n",
      "\n",
      "h==  [array([[ 0.02089557, -0.02384949,  0.02823262, ...,  0.00439688,\n",
      "         0.01063342,  0.02036572],\n",
      "       [ 0.00017994, -0.01018989,  0.02526652, ..., -0.00615683,\n",
      "        -0.00718532, -0.01362575],\n",
      "       [ 0.00752425,  0.01319972,  0.01500054, ...,  0.00459822,\n",
      "        -0.03604645,  0.02703289],\n",
      "       ...,\n",
      "       [ 0.00899788,  0.02166848,  0.00168932, ...,  0.01472035,\n",
      "         0.00252756, -0.00410829],\n",
      "       [ 0.04125884,  0.00260992, -0.03242766, ...,  0.05236889,\n",
      "        -0.00504639, -0.03357322],\n",
      "       [ 0.01974144, -0.00722586, -0.00369537, ...,  0.04788401,\n",
      "         0.00742996, -0.03797507]], dtype=float32), array([-0.23182426, -0.01929461,  0.03275681,  0.2825699 ,  0.08488464,\n",
      "        0.37731984, -0.14825028, -0.23235707, -0.1458046 ], dtype=float32)] \n",
      "\n",
      "\n",
      "type_of g ==  <class 'dict'> \n",
      "\n",
      "type_of h ==  <class 'list'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(learning_model_path+'learning_model.h5')\n",
    "#model = load_model('/home/atif/traffic_model_11_dec_1_filter.h5')\n",
    "layer_list =[]\n",
    "# f = open(learning_model_path+'model_file_info.txt', 'w') #uncomment it if you want to store all layer info at a time.\n",
    "\n",
    "def make_file(g1=0,h1=0,g_type=0,h_type=0, path=0, file_name=0):\n",
    "    f = open(path + file_name+'.txt','a')  # uncomment it if you want to store all layer info at a time.\n",
    "    f.write(\"layer_definition: \" + g1 + \"\\n\\n\")\n",
    "    f.write(\"layer_type: \" + g_type + \"\\n\\n\")\n",
    "    # f.write(\"\\n\")\n",
    "    f.write(\"layer_weight: \" + h1 + \"\\n\\n\")\n",
    "    f.write(\"weight_type: \" + h_type + \"\\n\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    \n",
    "    layer_list.append(h)\n",
    "    print (\"g== \",g,\"\\n\") #for printing layer name and verbal info\n",
    "\n",
    "    print (\"h== \",h,\"\\n\\n\") # for printing layer numeric value, eg: weight, bias value\n",
    "    print(\"type_of g == \",type(g),\"\\n\")\n",
    "    print(\"type_of h == \",type(h),\"\\n\")\n",
    "\n",
    "# below lines till f.close() used for writing in text file. To do this you have to uncomment the above line started with f.open() also.\n",
    "\n",
    "    g1=str(g) # declaring a string variable g1 to store the info of g\n",
    "    h1=str(h) #declaring a string variable h1 to store the info of h\n",
    "    g_type=str(type(g)) #declaring a string variable g1 to store the type of g\n",
    "    h_type=str(type(h)) #declaring a string variable h1 to store the type of h\n",
    "    make_file(g1, h1, g_type, h_type, learning_model_path, file_name=\"abc\")\n",
    "    # f.write(\"layer_definition: \"+g1+\"\\n\\n\")\n",
    "    # f.write(\"layer_type: \"+g_type+\"\\n\\n\")\n",
    "    # #f.write(\"\\n\")\n",
    "    # f.write(\"layer_weight: \"+h1+\"\\n\\n\")\n",
    "    # f.write(\"weight_type: \"+h_type+\"\\n\\n\\n\")\n",
    "    # f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_kernel: \n",
      " [[[[-0.67074907 -0.59329855 -0.53431404]\n",
      "   [-0.7462511  -0.3903124   0.06319907]\n",
      "   [-0.36227798 -0.09837703  0.5340042 ]]]\n",
      "\n",
      "\n",
      " [[[-0.26519078 -0.19100626  0.2422876 ]\n",
      "   [-0.20440044 -0.29235226  0.07251699]\n",
      "   [ 0.01618635 -0.33096606  0.04459456]]]\n",
      "\n",
      "\n",
      " [[[-1.5925051  -0.5391095  -0.56155765]\n",
      "   [-0.5556934   0.7204196   1.0512314 ]\n",
      "   [-0.18157953  1.145218    1.6162105 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.0586549   0.04417358 -0.21519895]\n",
      "   [-0.09233072 -0.32553932  0.0979021 ]\n",
      "   [ 0.238696   -0.09672035  0.1477777 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43710935 -0.6779395  -1.9064794 ]\n",
      "   [ 1.566656    0.9854658  -0.7540373 ]\n",
      "   [ 1.5616229   0.89573854 -0.4884904 ]]]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#From here the code has started which will extract every layer's info which you can use further in this file\n",
    "layer_list\n",
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose()\n",
    "print(\"conv_kernel: \\n\",conv_kernel,\"\\n\\n\")\n",
    "# print(\"conv_kernel shape:\\t\",conv_kernel.shape,\"\\n\\n\")\n",
    "# print(\"conv kernel dimension:\\t\",conv_kernel.ndim,\"\\n\\n\")\n",
    "# print(\"type_conv_kernel:\",type(conv_kernel),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "conv_bias=layer_list[0][1]\n",
    "# print(\"conv_bias_value: \",conv_bias)\n",
    "# print(\"conv_bias ndim: \",conv_bias.ndim,\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "dense_kernel=layer_list[2][0]\n",
    "#print(\"dense_kernel: \\n\",dense_kernel,\"\\n\\n\")\n",
    "#print(\"dense_kernel shape:\\t\",dense_kernel.shape,\"\\n\\n\")\n",
    "#print(\"dense_kernel dimension:\\t\",dense_kernel.ndim,\"\\n\\n\")\n",
    "#print(\"type_dense_kernel:\",type(dense_kernel),\"\\n\")\n",
    "#print(\"dense_kernel size: \",dense_kernel.size,\"\\n\")\n",
    "# dense_1_transpose=dense__1.transpose()\n",
    "# print(\"dense_1_transpose: \",dense_1_transpose,\"\\n\\n\")\n",
    "\n",
    "\n",
    "dense_bias=layer_list[2][1]\n",
    "#print(\"dense_bias: \",dense_bias)\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)\n",
    "dense_bias=dense_bias.reshape(1,NUM_CLASSES) # here chenge 5 to the number of your used class\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[-0.67074907, -0.59329855, -0.53431404],\n",
      "        [-0.7462511 , -0.3903124 ,  0.06319907],\n",
      "        [-0.36227798, -0.09837703,  0.5340042 ]]], dtype=float32), array([[[-0.26519078, -0.19100626,  0.2422876 ],\n",
      "        [-0.20440044, -0.29235226,  0.07251699],\n",
      "        [ 0.01618635, -0.33096606,  0.04459456]]], dtype=float32), array([[[-1.5925051 , -0.5391095 , -0.56155765],\n",
      "        [-0.5556934 ,  0.7204196 ,  1.0512314 ],\n",
      "        [-0.18157953,  1.145218  ,  1.6162105 ]]], dtype=float32), array([[[ 0.0586549 ,  0.04417358, -0.21519895],\n",
      "        [-0.09233072, -0.32553932,  0.0979021 ],\n",
      "        [ 0.238696  , -0.09672035,  0.1477777 ]]], dtype=float32), array([[[ 0.43710935, -0.6779395 , -1.9064794 ],\n",
      "        [ 1.566656  ,  0.9854658 , -0.7540373 ],\n",
      "        [ 1.5616229 ,  0.89573854, -0.4884904 ]]], dtype=float32)]\n",
      "[[[[-0.67074907 -0.59329855 -0.53431404]\n",
      "   [-0.7462511  -0.3903124   0.06319907]\n",
      "   [-0.36227798 -0.09837703  0.5340042 ]]]\n",
      "\n",
      "\n",
      " [[[-0.26519078 -0.19100626  0.2422876 ]\n",
      "   [-0.20440044 -0.29235226  0.07251699]\n",
      "   [ 0.01618635 -0.33096606  0.04459456]]]\n",
      "\n",
      "\n",
      " [[[-1.5925051  -0.5391095  -0.56155765]\n",
      "   [-0.5556934   0.7204196   1.0512314 ]\n",
      "   [-0.18157953  1.145218    1.6162105 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.0586549   0.04417358 -0.21519895]\n",
      "   [-0.09233072 -0.32553932  0.0979021 ]\n",
      "   [ 0.238696   -0.09672035  0.1477777 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43710935 -0.6779395  -1.9064794 ]\n",
      "   [ 1.566656    0.9854658  -0.7540373 ]\n",
      "   [ 1.5616229   0.89573854 -0.4884904 ]]]]\n",
      "4\n",
      "[ 0.63377595 -0.01135568 -0.02604145 -0.11364901 -0.0088685 ]\n",
      "convolution_kernel_filter: \n",
      " [[[-0.67074907 -0.59329855 -0.53431404]\n",
      "  [-0.74625111 -0.3903124   0.06319907]\n",
      "  [-0.36227798 -0.09837703  0.53400421]]\n",
      "\n",
      " [[-0.26519078 -0.19100626  0.24228761]\n",
      "  [-0.20440044 -0.29235226  0.07251699]\n",
      "  [ 0.01618635 -0.33096606  0.04459456]]\n",
      "\n",
      " [[-1.5925051  -0.53910953 -0.56155765]\n",
      "  [-0.55569339  0.72041959  1.05123138]\n",
      "  [-0.18157953  1.14521801  1.61621046]]\n",
      "\n",
      " [[ 0.0586549   0.04417358 -0.21519895]\n",
      "  [-0.09233072 -0.32553932  0.0979021 ]\n",
      "  [ 0.23869599 -0.09672035  0.14777771]]\n",
      "\n",
      " [[ 0.43710935 -0.67793947 -1.90647936]\n",
      "  [ 1.56665599  0.98546582 -0.75403732]\n",
      "  [ 1.56162286  0.89573854 -0.4884904 ]]] \n",
      "\n",
      "convolution_kernel_filter shape: (5, 3, 3) \tconvolution_kernel_filter ndim: 3 \n",
      "\n",
      "length of convolution_kernel_filter: 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose() # This has made to print it like a Matrix form. \n",
    "conv_kernel_list=[]\n",
    "for i in conv_kernel:\n",
    "#     print(i)\n",
    "    conv_kernel_list.append(i)\n",
    "#     for k in i:\n",
    "#         print(k)\n",
    "#         i_list.append(k)\n",
    "print(conv_kernel_list)\n",
    "conv_kernel_list_array=[]\n",
    "conv_kernel_list_array=np.array(conv_kernel_list)\n",
    "print(conv_kernel_list_array)\n",
    "# i_list_array=i_list_array.reshape(2,3,3)\n",
    "print(conv_kernel_list_array.ndim)\n",
    "\n",
    "\n",
    "# look conv_kernel_list_array[x][y][z][w] -- it is a 4 dim array. x is number of filter, y is full stack, z is number of row of each filter, w is each single element of every row\n",
    "for i in range(number_filter):\n",
    "    for j in range(filter_size):\n",
    "        for k in range(filter_size):\n",
    "            p = conv_kernel_list_array[i][0][j][k]\n",
    "            ww = str(p)\n",
    "            ww = ww.replace('[', '')\n",
    "            ww = ww.replace(']', '')\n",
    "            # ww = ww.strip()\n",
    "            f = open(learning_model_path + 'conv_kernel.txt','a')  # uncomment from here till f.close() if you want to save text file\n",
    "            f.write(ww)\n",
    "            if k<(filter_size-1):\n",
    "                f.write(\" \")\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Storing convolution bias, needed for cpp testing\n",
    "# =============================================================================\n",
    "\n",
    "conv_bias=layer_list[0][1]\n",
    "conv_bias_list=[]\n",
    "for i in conv_bias:\n",
    "    conv_bias_list.append(i)\n",
    "\n",
    "conv_bias_array=[]\n",
    "conv_bias_array=np.array(conv_bias_list)\n",
    "print(conv_bias_array)\n",
    "np.savetxt(learning_model_path+'conv_bias.txt', conv_bias_array, fmt='%1.8e',delimiter=' ')\n",
    "\n",
    "#for x in conv_bias_array:\n",
    "    #print(x)\n",
    "    \n",
    "    \n",
    "\n",
    "# =============================================================================\n",
    "# Storing dense kernel weight, needed for cpp testing\n",
    "# =============================================================================\n",
    " \n",
    "dense_kernel=layer_list[2][0]\n",
    "i_list=[] #declare a list to store the weight of dense kernel\n",
    "for i in dense_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i) #appended it in the declared list\n",
    "#     for k in i:\n",
    "# #         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[] #declared an array\n",
    "i_list_array=np.array(i_list) # store the value of list in the array\n",
    "#print(i_list_array)\n",
    "np.savetxt(learning_model_path+'dense_kernel.txt', i_list_array, fmt='%1.8e',delimiter=' ') #writing on a text file from array\n",
    "\n",
    "# %.8f #you can use it to get float value\n",
    "# fmt='%1.8e' #add this above line after i_list_aray\n",
    "\n",
    "# =============================================================================\n",
    "# Storing dense bias, needed for cpp testing\n",
    "# =============================================================================\n",
    "\n",
    "dense_bias=layer_list[2][1]\n",
    "dense_bias_list=[]\n",
    "for i in dense_bias:\n",
    "    dense_bias_list.append(i)\n",
    "\n",
    "dense_bias_array=[]\n",
    "dense_bias_array=np.array(dense_bias_list)\n",
    "#print(dense_bias_array)\n",
    "np.savetxt(learning_model_path+'dense_bias.txt', dense_bias_array, fmt='%1.8e',delimiter=' ')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Reshaping convolution kernel for further process\n",
    "# =============================================================================\n",
    "\n",
    "# print(\"conv_kernel:\\n\",conv_kernel,\"\\n\")\n",
    "# print(\"conv_kernel_shape:\",conv_kernel.shape,\"\\tconv_kernel ndim:\",conv_kernel.ndim,\"\\n\")\n",
    "# print(\"length of conv_kernel:\",len(conv_kernel),\"\\n\")\n",
    "\n",
    "conv_kernel_reshape=conv_kernel.reshape(number_filter,3,3) # 2 for 2 filter. change it according to your filter number\n",
    "# print(\"conv_kernel_reshape:\\n\",conv_kernel_reshape,\"\\n\")\n",
    "# print(\"conv_kernel_reshape shape:\",conv_kernel_reshape.shape,\"\\tconv_kernel_reshape ndim:\",conv_kernel_reshape.ndim,\"\\n\")\n",
    "# print(\"length of conv_kernel_reshape:\",len(conv_kernel_reshape[0]),\"\\n\")\n",
    "\n",
    "convolution_kernel_filter=[]\n",
    "convolution_kernel_filter=np.zeros((number_filter,3,3)) # 2 for 2 filter. change it according to your filter number\n",
    "convolution_kernel_filter[:,:,:]=np.array(conv_kernel_reshape)\n",
    "print(\"convolution_kernel_filter: \\n\",convolution_kernel_filter,\"\\n\")\n",
    "print(\"convolution_kernel_filter shape:\",convolution_kernel_filter.shape,\"\\tconvolution_kernel_filter ndim:\",convolution_kernel_filter.ndim,\"\\n\")\n",
    "print(\"length of convolution_kernel_filter:\",len(convolution_kernel_filter),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_(img, conv_filter, conv_bias_val, number_filter):\n",
    "#     print(\"\\nconv_ function start to work\\n\")\n",
    "#     print(\"conv_filter: \",conv_filter)\n",
    "#     print(\"eee: \",conv_bias_val, \"\\t num_filter: \", number_filter)\n",
    "    filter_size = conv_filter.shape[1] #output is 3\n",
    "#    print(\"filter_size: \",filter_size)\n",
    "#    print(\"img shape: \",img.shape)\n",
    "    result = np.zeros((img.shape))\n",
    "#    Looping through the image to apply the convolution operation.\n",
    "    \n",
    "    for x in range(number_filter):  # this loop take decision looping will be continued to num_filter times. Why?? because then it will take one by one \n",
    "                                            # all filter and perform the convolution.\n",
    "        \n",
    "        for r in np.uint16(np.arange(filter_size/2.0,img.shape[0]-filter_size/2.0+1)):\n",
    "        \n",
    "            for c in np.uint16(np.arange(filter_size/2.0,img.shape[1]-filter_size/2.0+1)):\n",
    "            \n",
    "                curr_region = img[r-np.uint16(np.floor(filter_size/2.0)):r+np.uint16(np.ceil(filter_size/2.0)), c-np.uint16(np.floor(filter_size/2.0)):c+np.uint16(np.ceil(filter_size/2.0))]\n",
    "        \n",
    "                #Element-wise multipliplication between the current region and the filter.\n",
    "            \n",
    "                curr_result = curr_region * conv_filter\n",
    "#                 print(\"curr_result: \",curr_result)\n",
    "#                 curr_result= curr_result+x\n",
    "                \n",
    "#             print(\"conv_bias: \",conv_bias_new)\n",
    "#                 print(\"new curr res: \",curr_result)\n",
    "                conv_sum = np.sum(curr_result) #Summing the result of multiplication.\n",
    "                result[r, c] = conv_sum#Saving the summation in the convolution layer feature map.\n",
    "#        print(\"now x is: \",x)\n",
    "        #print(curr_region)\n",
    "    #Clipping the outliers of the result matrix.\n",
    "#     print(\"conv_sum_shape: \",conv_sum.shape)\n",
    "    final_result = result[np.uint16(filter_size/2.0):result.shape[0]-np.uint16(filter_size/2.0),np.uint16(filter_size/2.0):result.shape[1]-np.uint16(filter_size/2.0)]\n",
    "#     print(\"bias: \", conv_bias_val)\n",
    "    final_result = final_result+conv_bias_val\n",
    "#     print(\"\\nconv_ function finish\\n\")\n",
    "    return final_result\n",
    "\n",
    "def conv(img, conv_filter, conv_bias_array, number_filter):\n",
    "    print(\"in func: \",img.shape,\"\\t\",conv_filter.shape)\n",
    "#    print(\"\\nconv function start to work\")\n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Error: Number of channels in both image and filter must match.\")\n",
    "            sys.exit()\n",
    "    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\n",
    "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')\n",
    "        sys.exit()\n",
    "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
    "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')\n",
    "        sys.exit()\n",
    "\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    feature_maps = np.zeros((img.shape[0]-conv_filter.shape[1]+1, img.shape[1]-conv_filter.shape[1]+1, conv_filter.shape[0]))\n",
    "\n",
    "    # Convolving the image by the filter(s).\n",
    "    \n",
    "    for filter_num in range(conv_filter.shape[0]): # number_of_filter times looping will be occurred \n",
    "#         print(\"filter num: \",filter_num)\n",
    "#        print(\"Filter \", filter_num + 1)\n",
    "        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank. In every looping new filter will come here\n",
    "#         print(\"curr_filter: \",curr_filter)\n",
    "#         print(\"curr_fiter_shape: \",curr_filter.shape)\n",
    "#         print(\"length of curr_fiter_shape: \",len(curr_filter.shape))\n",
    "\n",
    "\n",
    "        if len(curr_filter.shape) > 2: # RGB filter/ Used for training RGB images\n",
    "            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\n",
    "            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\n",
    "                conv_map = conv_map + conv_(img[:, :, ch_num], \n",
    "                                  curr_filter[:, :, ch_num])\n",
    "        else: # There is just a single channel in the filter. Black and White\n",
    "#            print(\"\\nGo to conv_ function \")\n",
    "            bias_conv = conv_bias_array[filter_num]\n",
    "#             print(\"bias_conv: \",bias_conv)\n",
    "            conv_map = conv_(img, curr_filter, bias_conv, number_filter)\n",
    "        \n",
    "        \n",
    "#         print(\"conv_map shape: \", conv_map.shape)\n",
    "            \n",
    "        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\n",
    "#         print(\"feature_maps from conv_map: \",feature_maps)\n",
    "    return feature_maps # Returning all feature maps.\n",
    "\n",
    "\n",
    "def relu(feature_map):\n",
    "    #Preparing the output of the ReLU activation function.\n",
    "    relu_out = np.zeros(feature_map.shape)\n",
    "    for map_num in range(feature_map.shape[-1]):\n",
    "        for r in np.arange(0,feature_map.shape[0]):\n",
    "            for c in np.arange(0, feature_map.shape[1]):\n",
    "                relu_out[r, c, map_num] = np.max([feature_map[r, c, map_num], 0])\n",
    "    return relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = test_image_path\n",
    "# path = r'/home/atif/training_by_several_learning_process/number_classify/rgb_2_gray/Image-classification/test_image/'\n",
    "#for image in img_path:\n",
    "img_path = glob.glob(path+ '/*'+str(img_type))\n",
    "\n",
    "def do_math(img_path, convolution_kernel_filter,conv_bias_array, IMG_SIZE,number_filter, NUM_CLASSES, total_time,dense_kernel, dense_bias):\n",
    "    for image_number, image in enumerate(img_path):\n",
    "        #    print(\"\\nnum of image is: \",image_number) #It will return current image number. But careful it's cunting starts from zero so don't forget to add 1\n",
    "        print(\"\\nName of loaded image: \", image)\n",
    "        # =============================================================================\n",
    "        #     X_test=[]\n",
    "        #     X_test.append(preprocess_img(io.imread(image)))\n",
    "        #     X_test = np.array(X_test)\n",
    "        #     print(\"\\nshape: \",X_test.shape)\n",
    "        #     X_test = X_test.reshape(IMG_SIZE,IMG_SIZE)\n",
    "        #     plt.imshow(X_test)\n",
    "        # =============================================================================\n",
    "\n",
    "        X_test = []\n",
    "        #    cv_img = []\n",
    "        n = cv2.imread(image)\n",
    "        n = cv2.resize(n, (IMG_SIZE, IMG_SIZE))\n",
    "        n = cv2.cvtColor(n, cv2.COLOR_RGB2GRAY)\n",
    "        #    n = cv2.normalize(n, n, 0, 255, cv2.NORM_MINMAX)\n",
    "        n = cv2.normalize(n, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "\n",
    "        X_test.append(n)\n",
    "        X_test = np.array(X_test)\n",
    "        X_test = X_test.reshape(IMG_SIZE, IMG_SIZE)\n",
    "        X_test = np.rollaxis(X_test, -1)\n",
    "        print(\"img shape: \",X_test.shape,\" len fo shape: \",len(X_test.shape),\" ndim: \",X_test.ndim)\n",
    "        print(\"conv kernel shape: \",convolution_kernel_filter.shape,\" len fo shape: \",len(convolution_kernel_filter.shape),\" ndim: \",convolution_kernel_filter.ndim)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        feature = conv(img=X_test, conv_filter=convolution_kernel_filter, conv_bias_array=conv_bias_array, number_filter=number_filter)  # conv function calling\n",
    "        \n",
    "        print(\"feature_shape: \",feature.shape,\" feature ndim: \",feature.ndim)\n",
    "        \n",
    "#         print(\"---------\\n\",feature)\n",
    "        relu_out = relu(feature)  # relu function calling\n",
    "\n",
    "        # output of feature map / conv function\n",
    "\n",
    "        #    print(\"\\nfeature shape: \\n\",feature.shape)\n",
    "\n",
    "        #     x_feature_map=np.flipud(feature[0])\n",
    "\n",
    "        transpose_feature_map = feature.transpose()\n",
    "\n",
    "        #    print(\"\\ntranspose_feature_map shape: \",transpose_feature_map.shape)\n",
    "        #     plt.imshow(transpose_feature_map[0])\n",
    "        #    print(\"\\ntranspose_feature_map: \\n\",transpose_feature_map)\n",
    "\n",
    "        #    print(\"\\nrelu_out shape: \",relu_out.shape)\n",
    "        relu_out_transpose = relu_out.transpose()\n",
    "        print(\"\\nrelu_out_transpose shape: \",relu_out_transpose.shape)\n",
    "#         print(\"---------\\n\",relu_out_transpose)\n",
    "        #     plt.imshow(relu_out_transpose[0])\n",
    "        #    print(\"\\nrelu_out_transpose:\\n\",relu_out_transpose)\n",
    "\n",
    "        # =============================================================================\n",
    "        #      matrix multiplication with dense kernel and relu o/p\n",
    "        # =============================================================================\n",
    "\n",
    "        flatten_relu_out_transpose = relu_out_transpose.reshape(1,number_filter * 46 * 46)  # if you don't do padd on input image please make it 46*46. how 46 came?\n",
    "        # the formula of output size. and 2 for 2 filter\n",
    "#         print(\"\\nflatten_relu_out_transpose shape: \\n\",flatten_relu_out_transpose.shape)\n",
    "\n",
    "#         print(\"\\ndense_kernel shape: \\n\",dense_kernel.shape,\"\\n\")\n",
    "\n",
    "        matmul_flatt_rel_dense_kernel = np.matmul(flatten_relu_out_transpose, dense_kernel)\n",
    "#         print(\"\\nmatmul_soft_dense_kernel shape: \\n\",matmul_flatt_rel_dense_kernel.shape,\"\\n\")\n",
    "#         print(\"\\nmatmul_soft_dense_kernel: \\n\",matmul_flatt_rel_dense_kernel,\"\\n\")\n",
    "\n",
    "        dense_bias_array = np.array(dense_bias)\n",
    "        dense_bias_array = dense_bias_array.reshape(1, NUM_CLASSES)  # 9 for 9 class\n",
    "#         print(\"\\ndense_bias_array: \\n\",dense_bias_array,\"\\n\")\n",
    "\n",
    "        add_matmul_flatt_rel_dense_kernel_and_dense_bias_array = matmul_flatt_rel_dense_kernel + dense_bias_array\n",
    "\n",
    "#         print(\"\\nvalue add_matmul_flatt_rel_dense_kernel_and_dense2_array: \\n\",add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "\n",
    "        def softmax_fn(input_array):\n",
    "            e_x = np.exp(input_array - np.max(input_array))\n",
    "            return e_x / e_x.sum(axis=len(e_x.shape) - 1)\n",
    "\n",
    "        op = softmax_fn(add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "        print(\"output of FC layer: \",op,\"\\n\")\n",
    "\n",
    "        # =============================================================================\n",
    "        #     Following code for finding class\n",
    "        # =============================================================================\n",
    "\n",
    "        m = 0\n",
    "        k = 0\n",
    "        # op=[[0.17095664, 0.24349895, 0.172376,   0.19243606, 0.62073235]]\n",
    "        # op=np.array(op)\n",
    "        # print(op.shape)\n",
    "        # print(type(op))\n",
    "\n",
    "        for h in op:\n",
    "\n",
    "            for index, j in enumerate(h):\n",
    "\n",
    "                o = j\n",
    "                # print(o)\n",
    "                if o > m:\n",
    "                    m = o\n",
    "                    #                print(m)\n",
    "                    k = index\n",
    "                else:\n",
    "                    pass\n",
    "        print('class:', k)\n",
    "        end = time.time()\n",
    "        elapsed_time = round((end - start) * 1000, 3)\n",
    "        total_time += elapsed_time\n",
    "        # normally gives time in second. multiply or divide to change unit of time\n",
    "        print(\"\\nElapsed Time: \", elapsed_time, \" milliseconds and total time is: \", total_time, \" milliseconds\")\n",
    "        print(\"\\n-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    return image_number, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of loaded image:  /media/atif/BE0E05910E0543BD/University of Bremen MSc/item_project/Image-classification/test_image/20_speed.ppm\n",
      "img shape:  (48, 48)  len fo shape:  2  ndim:  2\n",
      "conv kernel shape:  (5, 3, 3)  len fo shape:  3  ndim:  3\n",
      "in func:  (48, 48) \t (5, 3, 3)\n",
      "feature_shape:  (46, 46, 5)  feature ndim:  3\n",
      "\n",
      "relu_out_transpose shape:  (5, 46, 46)\n",
      "output of FC layer:  [[2.01219049e-04 6.05785105e-01 1.56110293e-04 1.47713526e-08\n",
      "  6.11215573e-03 2.60555872e-05 3.64587386e-01 5.76833987e-03\n",
      "  1.73636137e-02]] \n",
      "\n",
      "class: 1\n",
      "\n",
      "Elapsed Time:  1020.799  milliseconds and total time is:  185142.094  milliseconds\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Name of loaded image:  /media/atif/BE0E05910E0543BD/University of Bremen MSc/item_project/Image-classification/test_image/30_speed.ppm\n",
      "img shape:  (48, 48)  len fo shape:  2  ndim:  2\n",
      "conv kernel shape:  (5, 3, 3)  len fo shape:  3  ndim:  3\n",
      "in func:  (48, 48) \t (5, 3, 3)\n",
      "feature_shape:  (46, 46, 5)  feature ndim:  3\n",
      "\n",
      "relu_out_transpose shape:  (5, 46, 46)\n",
      "output of FC layer:  [[2.30943039e-03 6.11381905e-01 2.95771516e-01 6.20261214e-06\n",
      "  3.30262088e-02 5.70476743e-02 3.00454404e-04 4.41052645e-06\n",
      "  1.52197961e-04]] \n",
      "\n",
      "class: 1\n",
      "\n",
      "Elapsed Time:  998.924  milliseconds and total time is:  186141.018  milliseconds\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Total image number is:  2\n",
      "\n",
      "Total time for all classification:  186141.018  milliseconds\n",
      "\n",
      "Average time taken for per image classification:  93070.509  milliseconds\n"
     ]
    }
   ],
   "source": [
    "image_number, total_time = do_math(img_path, convolution_kernel_filter, conv_bias_array, IMG_SIZE,number_filter, NUM_CLASSES, total_time,dense_kernel, dense_bias)\n",
    "    \n",
    "print(\"\\nTotal image number is: \",image_number+1)\n",
    "print(\"\\nTotal time for all classification: \",total_time,\" milliseconds\")\n",
    "total_image=image_number+1\n",
    "print(\"\\nAverage time taken for per image classification: \",round((total_time/total_image),3),\" milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = np.zeros((5,5))\n",
    "fil = np.ones((3,3))\n",
    "pic = pic+2\n",
    "result = np.zeros((pic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size= fil.shape[1]\n",
    "img_1 = pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "for x in range(2):  # to get the value of convolution bias\n",
    "#         print(\"i am the conv_bias: \",x)\n",
    "        \n",
    "        for r in np.uint16(np.arange(filter_size/2.0,img_1.shape[0]-filter_size/2.0+1)):\n",
    "        \n",
    "            for c in np.uint16(np.arange(filter_size/2.0,img_1.shape[1]-filter_size/2.0+1)):\n",
    "            \n",
    "                curr_region = img_1[r-np.uint16(np.floor(filter_size/2.0)):r+np.uint16(np.ceil(filter_size/2.0)), c-np.uint16(np.floor(filter_size/2.0)):c+np.uint16(np.ceil(filter_size/2.0))]\n",
    "        \n",
    "                #Element-wise multipliplication between the current region and the filter.\n",
    "            \n",
    "                curr_result = curr_region * fil\n",
    "                conv_sum = np.sum(curr_result) #Summing the result of multiplication.\n",
    "                result[r, c] = conv_sum#Saving the summation in the convolution layer feature map.\n",
    "                print(result[r,c])\n",
    "        final_result = result[np.uint16(filter_size/2.0):result.shape[0]-np.uint16(filter_size/2.0),np.uint16(filter_size/2.0):result.shape[1]-np.uint16(filter_size/2.0)]\n",
    "#    print(\"\\nconv_ function finish\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18., 18., 18.],\n",
       "       [18., 18., 18.],\n",
       "       [18., 18., 18.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract weight from trained model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/home/atif/image_classification_c++/multi_filter_cpp/traffic_2_filter_no_pad_gray_ep_100_for_cpp.h5')\n",
    "#model = load_model('/home/atif/traffic_model_11_dec_1_filter.h5')\n",
    "layer_list =[]\n",
    "# f = open('/home/atif/path_for_storing_all_layer_info.txt', 'w') #uncomment it if you want to store all layer info at a time.\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    \n",
    "    layer_list.append(h)\n",
    "#     print (\"g== \",g,\"\\n\") #for printing layer name and verbal info\n",
    "\n",
    "#     print (\"h== \",h,\"\\n\\n\") # for printing layer numeric value, eg: weight, bias value\n",
    "#     print(\"type_of g == \",type(g),\"\\n\")\n",
    "#     print(\"type_of h == \",type(h),\"\\n\")\n",
    "\n",
    "# below lines till f.close() used for writing in text file. To do this you have to uncomment the above line started with f.open() also.\n",
    "\n",
    "#     g1=str(g) # declaring a string variable g1 to store the info of g\n",
    "#     h1=str(h) #declaring a string variable h1 to store the info of h\n",
    "#     g_type=str(type(g)) #declaring a string variable g1 to store the type of g\n",
    "#     h_type=str(type(h)) #declaring a string variable h1 to store the type of h\n",
    "    \n",
    "#     f.write(\"layer_definition: \"+g1+\"\\n\\n\")\n",
    "#     f.write(\"layer_type: \"+g_type+\"\\n\\n\")\n",
    "#     #f.write(\"\\n\")\n",
    "#     f.write(\"layer_weight: \"+h1+\"\\n\\n\")\n",
    "#     f.write(\"weight_type: \"+h_type+\"\\n\\n\\n\")\n",
    "#     f.write(\"\\n\")\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display extracted weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose()\n",
    "#print(\"conv_kernel: \\n\",conv_kernel,\"\\n\\n\")\n",
    "#print(\"conv_kernel shape:\\t\",conv_kernel.shape,\"\\n\\n\")\n",
    "#print(\"conv kernel dimension:\\t\",conv_kernel.ndim,\"\\n\\n\")\n",
    "#print(\"type_conv_kernel:\",type(conv_kernel),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "conv_bias=layer_list[0][1]\n",
    "#print(\"conv_bias_value: \",conv_bias)\n",
    "#print(\"conv_bias ndim: \",conv_bias.ndim,\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "dense_kernel=layer_list[2][0]\n",
    "#print(\"dense_kernel: \\n\",dense_kernel,\"\\n\\n\")\n",
    "#print(\"dense_kernel shape:\\t\",dense_kernel.shape,\"\\n\\n\")\n",
    "#print(\"dense_kernel dimension:\\t\",dense_kernel.ndim,\"\\n\\n\")\n",
    "#print(\"type_dense_kernel:\",type(dense_kernel),\"\\n\")\n",
    "#print(\"dense_kernel size: \",dense_kernel.size,\"\\n\")\n",
    "# dense_1_transpose=dense__1.transpose()\n",
    "# print(\"dense_1_transpose: \",dense_1_transpose,\"\\n\\n\")\n",
    "\n",
    "\n",
    "dense_bias=layer_list[2][1]\n",
    "#print(\"dense_bias: \",dense_bias)\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)\n",
    "dense_bias=dense_bias.reshape(1,9) # here chenge 5 to the number of your used class\n",
    "#print(\"dense_bias_shape: \",dense_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing convolution kernel weight in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel=layer_list[0][0]\n",
    "conv_kernel=conv_kernel.transpose() # This has made to print it like a Matrix form. \n",
    "i_list=[]\n",
    "for i in conv_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i)\n",
    "#     for k in i:\n",
    "#         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[]\n",
    "i_list_array=np.array(i_list)\n",
    "# print(i_list_array.shape)\n",
    "# i_list_array=i_list_array.reshape(2,3,3)\n",
    "# print(i_list_array.ndim)\n",
    "\n",
    "for p in i_list_array:\n",
    "#     for a in p:\n",
    "#         print(a)\n",
    "#    print(p)\n",
    "    ww=str(p)\n",
    "    ww=ww.replace('[','')\n",
    "    ww=ww.replace(']','')\n",
    "    #f=open('/home/atif/conv_k_spy.txt','a') #uncomment from here till f.close() if you want to save text file\n",
    "    #f.write(ww)\n",
    "    #f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing convolution kernel bias value in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bias=layer_list[0][1]\n",
    "conv_bias_list=[]\n",
    "for i in conv_bias:\n",
    "    conv_bias_list.append(i)\n",
    "\n",
    "conv_bias_array=[]\n",
    "conv_bias_array=np.array(conv_bias_list)\n",
    "#print(conv_bias_array)\n",
    "#np.savetxt('/home/atif/conv_b_spy.txt', conv_bias_array, fmt='%1.8e',delimiter=' ')\n",
    "\n",
    "#for x in conv_bias_array:\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Dense kernel weight in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_kernel=layer_list[2][0]\n",
    "i_list=[] #declare a list to store the weight of dense kernel\n",
    "for i in dense_kernel:\n",
    "#     print(i)\n",
    "    i_list.append(i) #appended it in the declared list\n",
    "#     for k in i:\n",
    "# #         print(k)\n",
    "#         i_list.append(k)\n",
    "# print(i_list)\n",
    "i_list_array=[] #declared an array\n",
    "i_list_array=np.array(i_list) # store the value of list in the array\n",
    "#print(i_list_array)\n",
    "#np.savetxt('/home/atif/dense_k_spy.txt', i_list_array, fmt='%1.8e',delimiter=' ') #writing on a text file from array\n",
    "\n",
    "# %.8f #you can use it to get float value\n",
    "# fmt='%1.8e' #add this above line after i_list_aray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Dense kernel bias value in a text file to use in CPP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_bias=layer_list[2][1]\n",
    "dense_bias_list=[]\n",
    "for i in dense_bias:\n",
    "    dense_bias_list.append(i)\n",
    "\n",
    "dense_bias_array=[]\n",
    "dense_bias_array=np.array(dense_bias_list)\n",
    "#print(dense_bias_array)\n",
    "#np.savetxt('/home/atif/dense_b_spy.txt', dense_bias_array, fmt='%1.8e',delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping convolution kernel for further process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"conv_kernel:\\n\",conv_kernel,\"\\n\")\n",
    "#print(\"conv_kernel_shape:\",conv_kernel.shape,\"\\tconv_kernel ndim:\",conv_kernel.ndim,\"\\n\")\n",
    "#print(\"length of conv_kernel:\",len(conv_kernel),\"\\n\")\n",
    "\n",
    "conv_kernel_reshape=conv_kernel.reshape(2,3,3) # 2 for 2 filter. change it according to your filter number\n",
    "#print(\"conv_kernel_reshape:\\n\",conv_kernel_reshape,\"\\n\")\n",
    "#print(\"conv_kernel_reshape shape:\",conv_kernel_reshape.shape,\"\\tconv_kernel_reshape ndim:\",conv_kernel_reshape.ndim,\"\\n\")\n",
    "#print(\"length of conv_kernel_reshape:\",len(conv_kernel_reshape[0]),\"\\n\")\n",
    "\n",
    "convolution_kernel_filter=[]\n",
    "convolution_kernel_filter=np.zeros((2,3,3)) # 2 for 2 filter. change it according to your filter number\n",
    "convolution_kernel_filter[:,:,:]=np.array(conv_kernel_reshape)\n",
    "#print(\"convolution_kernel_filter: \\n\",convolution_kernel_filter,\"\\n\")\n",
    "#print(\"convolution_kernel_filter shape:\",convolution_kernel_filter.shape,\"\\tconvolution_kernel_filter ndim:\",convolution_kernel_filter.ndim,\"\\n\")\n",
    "#print(\"length of convolution_kernel_filter:\",len(convolution_kernel_filter),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for Classification\n",
    "## At first processing image, Convolution and apply Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/50_speed.ppm\n",
      "Filter  1\n",
      "Filter  2\n",
      "3.466926483846102e-142\n",
      "2.3085899666969084e-48\n",
      "6.995688263318184e-30\n",
      "3.8409075116573936e-15\n",
      "0.9999999999999962\n",
      "class: 4\n",
      "\n",
      "Name of loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/20_speed.ppm\n",
      "Filter  1\n",
      "Filter  2\n",
      "1.4442679059689178e-133\n",
      "2.518911831904704e-30\n",
      "1.3016192821246158e-15\n",
      "0.046888826826912006\n",
      "0.9531111731730867\n",
      "class: 4\n",
      "\n",
      "Name of loaded image:  /home/atif/image_classification_c++/multi_filter_cpp/test_image/stop.ppm\n",
      "Filter  1\n",
      "Filter  2\n",
      "3.380052453539173e-138\n",
      "9.902191131949987e-56\n",
      "1.4209070255903226e-31\n",
      "1.0\n",
      "class: 3\n"
     ]
    }
   ],
   "source": [
    "def preprocess_img(img):\n",
    "#     uncomment following 5 lines for rgb testing and comment out the rgb2gray line\n",
    "#     Histogram normalization in y\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "    img = rgb2gray(img) #rgb to gray conversion\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def conv_(img, conv_filter):\n",
    "#     print(\"\\nconv_ function start to work\\n\")\n",
    "    filter_size = conv_filter.shape[1] #output is 3\n",
    "#     print(\"filter_size: \",filter_size)\n",
    "#     print(\"img shape: \",img.shape)\n",
    "    result = np.zeros((img.shape))\n",
    "    #Looping through the image to apply the convolution operation.\n",
    "    \n",
    "    for x in conv_bias_array:  # to get the value of convolution bias\n",
    "#         print(\"i am the conv_bias: \",x)\n",
    "        \n",
    "        for r in np.uint16(np.arange(filter_size/2.0,img.shape[0]-filter_size/2.0+1)):\n",
    "        \n",
    "            for c in np.uint16(np.arange(filter_size/2.0,img.shape[1]-filter_size/2.0+1)):\n",
    "            \n",
    "                curr_region = img[r-np.uint16(np.floor(filter_size/2.0)):r+np.uint16(np.ceil(filter_size/2.0)), c-np.uint16(np.floor(filter_size/2.0)):c+np.uint16(np.ceil(filter_size/2.0))]\n",
    "        \n",
    "                #Element-wise multipliplication between the current region and the filter.\n",
    "            \n",
    "                curr_result = curr_region * conv_filter\n",
    "#             print(\"curr_result: \",curr_result)\n",
    "                curr_result= curr_result+x\n",
    "                \n",
    "#             print(\"conv_bias: \",conv_bias_new)\n",
    "#                 print(\"new curr res: \",curr_result)\n",
    "                conv_sum = np.sum(curr_result) #Summing the result of multiplication.\n",
    "                result[r, c] = conv_sum#Saving the summation in the convolution layer feature map.\n",
    "#             print(\"conv_sum_shape: \",conv_sum.shape)\n",
    "#         print(\"now x is: \",x)\n",
    "        #print(curr_region)\n",
    "    #Clipping the outliers of the result matrix.\n",
    "    final_result = result[np.uint16(filter_size/2.0):result.shape[0]-np.uint16(filter_size/2.0),np.uint16(filter_size/2.0):result.shape[1]-np.uint16(filter_size/2.0)]\n",
    "#     print(\"\\nconv_ function finish\\n\")\n",
    "    return final_result\n",
    "\n",
    "\n",
    "\n",
    "def conv(img, conv_filter):\n",
    "#     print(\"\\nconv function start to work\")\n",
    "    \n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Error: Number of channels in both image and filter must match.\")\n",
    "            sys.exit()\n",
    "    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\n",
    "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')\n",
    "        sys.exit()\n",
    "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
    "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')\n",
    "        sys.exit()\n",
    "\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    feature_maps = np.zeros((img.shape[0]-conv_filter.shape[1]+1, img.shape[1]-conv_filter.shape[1]+1, conv_filter.shape[0]))\n",
    "\n",
    "    # Convolving the image by the filter(s).\n",
    "    \n",
    "    for filter_num in range(conv_filter.shape[0]):\n",
    "#         print(\"filter num: \",filter_num)\n",
    "        print(\"Filter \", filter_num + 1)\n",
    "        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.\n",
    "#         print(curr_filter)\n",
    "        #print(\"curr_fiter_shape: \",curr_filter.shape)\n",
    "#         print(\"length of curr_fiter_shape: \",len(curr_filter.shape))\n",
    "\n",
    "\n",
    "        if len(curr_filter.shape) > 2:\n",
    "            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\n",
    "            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\n",
    "                conv_map = conv_map + conv_(img[:, :, ch_num], \n",
    "                                  curr_filter[:, :, ch_num])\n",
    "        else: # There is just a single channel in the filter.\n",
    "#             print(\"\\nGo to conv_ function \")\n",
    "            conv_map = conv_(img, curr_filter)\n",
    "            \n",
    "        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\n",
    "#         print(\"feature_maps from conv_map: \",feature_maps)\n",
    "    return feature_maps # Returning all feature maps.\n",
    "\n",
    "\n",
    "def relu(feature_map):\n",
    "    #Preparing the output of the ReLU activation function.\n",
    "    relu_out = np.zeros(feature_map.shape)\n",
    "    for map_num in range(feature_map.shape[-1]):\n",
    "        for r in np.arange(0,feature_map.shape[0]):\n",
    "            for c in np.arange(0, feature_map.shape[1]):\n",
    "                relu_out[r, c, map_num] = np.max([feature_map[r, c, map_num], 0])\n",
    "    return relu_out\n",
    "\n",
    "\n",
    "\n",
    "path = r'/home/atif/image_classification_c++/multi_filter_cpp/test_image/'\n",
    "\n",
    "img_path = glob.glob(path+ '/*.ppm')\n",
    "for image in img_path:\n",
    "    print(\"\\nName of loaded image: \",image)\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    feature=conv(img=X_test,conv_filter=convolution_kernel_filter) #conv function calling\n",
    "    relu_out=relu(feature) # relu function calling\n",
    "    \n",
    "    # output of feature map / conv function\n",
    "\n",
    "#     print(\"\\nfeature shape: \\n\",feature.shape)\n",
    "\n",
    "    # x_feature_map=np.flipud(feature[0])\n",
    "    transpose_feature_map=feature.transpose()\n",
    "#     print(\"\\ntranspose_feature_map shape: \",transpose_feature_map.shape)\n",
    "#     plt.imshow(transpose_feature_map[0])\n",
    "#     print(\"\\ntranspose_feature_map: \\n\",transpose_feature_map)\n",
    "    \n",
    "#     print(\"\\nrelu_out shape: \",relu_out.shape)\n",
    "    relu_out_transpose=relu_out.transpose()\n",
    "#     print(\"\\nrelu_out_transpose shape: \",relu_out_transpose.shape)\n",
    "#     plt.imshow(relu_out_transpose[0])\n",
    "#     print(\"\\nrelu_out_transpose:\\n\",relu_out_transpose)\n",
    "    \n",
    "# Matrix Multiplication with Dense kernel weight and Convolved Image\n",
    "\n",
    "    flatten_relu_out_transpose=relu_out_transpose.reshape(1,2*46*46)  #if you don't do padd on input image please make it 46*46. how 46 came? \n",
    "                                                                                    #the formula of output size. and 2 for 2 feature map. Here 2 filter so 2 featue map\n",
    "#     print(\"\\nflatten_relu_out_transpose shape: \\n\",flatten_relu_out_transpose.shape)\n",
    "#     print(\"\\ndense_kernel shape: \\n\",dense_kernel.shape,\"\\n\")\n",
    "    matmul_flatt_rel_dense_kernel=np.matmul(flatten_relu_out_transpose,dense_kernel)\n",
    "#     print(\"\\nmatmul_soft_dense_kernel shape: \\n\",matmul_flatt_rel_dense_kernel.shape,\"\\n\")\n",
    "#     print(\"\\nmatmul_soft_dense_kernel: \\n\",matmul_flatt_rel_dense_kernel,\"\\n\")\n",
    "\n",
    "    dense_bias_array=np.array(dense_bias)\n",
    "    dense_bias_array=dense_bias_array.reshape(1,9) # 9 for 9 class\n",
    "#     print(\"\\ndense_bias_array: \\n\",dense_bias_array,\"\\n\")\n",
    "\n",
    "    add_matmul_flatt_rel_dense_kernel_and_dense_bias_array=matmul_flatt_rel_dense_kernel+dense_bias_array\n",
    "#     print(\"\\nvalue add_matmul_flatt_rel_dense_kernel_and_dense2_array: \\n\",add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "    \n",
    "    def softmax_fn(input_array):\n",
    "        e_x=np.exp(input_array-np.max(input_array))\n",
    "        return e_x/e_x.sum(axis=len(e_x.shape)-1)\n",
    "\n",
    "    op= softmax_fn(add_matmul_flatt_rel_dense_kernel_and_dense_bias_array)\n",
    "#     print(\"output of FC layer: \",op,\"\\n\")\n",
    "    \n",
    "#   Show class of loaded image\n",
    "\n",
    "    m=0\n",
    "    k=0\n",
    "    # op=[[0.17095664, 0.24349895, 0.172376,   0.19243606, 0.62073235]]\n",
    "    # op=np.array(op)\n",
    "    # print(op.shape)\n",
    "    # print(type(op))\n",
    "\n",
    "    for h in op:\n",
    "        for index,j in enumerate(h):\n",
    "            o=j\n",
    "            #print(o)\n",
    "            if o>m:\n",
    "                m=o\n",
    "                print(m)\n",
    "                k=index\n",
    "            else:\n",
    "                pass\n",
    "    print('class:',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
